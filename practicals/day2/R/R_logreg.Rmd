---
title: "Logistic regression in R"
author: "Gerko Vink"
output: 
   html_document:
    toc: true
    toc_depth: 5
    toc_float: true
    number_sections: false
---

<style type="text/css">
  
body{ /* Normal  */
  font-size: 12px;
  }
td {  /* Table  */
  font-size: 12px;
}
h1.title {
  font-size: 18px;
  color: DarkBlue;
}
h1 { /* Header 1 */
  font-size: 18px;
}
h2 { /* Header 2 */
  font-size: 18px;
}
h3 { /* Header 3 */
  font-size: 18px;
}
code.r{ /* Code block */
  font-size: 12px;
}
pre { /* Code block - determines code spacing between lines */
  font-size: 14px;
}
</style>

---

# Packages used
```{r message = FALSE, warning=FALSE}
library(tidyverse)# for all things useful
library(magrittr) # pipes
library(ISLR)     # for the Default data
library(DAAG)     # for the headInjury data
library(ggplot2)  # plotting device
library(GGally)   # for ggpairs()
library(caret)    # for confusionMatrix()
```

---

In this exercise we focus on logistic regression. We use logistic regression when we would like to model a dichotomous response: an outcome variable that takes only two levels. The predictors can - as with linear regression - be continuous and/or categorical/dichotomous. 

---

# Default data

We start with the `Default` data set from the book [Introduction to Statitistical Learning](https://www.statlearning.com) by James, Witten, Hastie & Tibshirani (2021 - 2nd edition). The data set contains  information about `default` on creditcard payments for `students` and non-students, with for every respondent measurements on `income` and creditcard `balance`. 

---

_1_ **Inspect the `Default` data set**

When we look at the summary statistics for the data variables, we find the following descriptive statistics:
```{r}
Default %>% summary
```

We see that there are no missing values in the data. We also get information about the means and the standard deviation for `balance` and `income`. We get no information on these statistics for the categorical (in this case dichotomous) variables, as it would not make sense. The minimum and maximum values can be quickly inspected; these values can often be used to spot implausible or impossible values. For example, a negative income out of labour would not be possible. On the other hand, a negative credit card balance would be possible if someone were e.g. reimbursed on their card after a paymant had been made. In this case there are no negative `balance` or `income` values. 

We see that 9667 out of 10000 cases are not defaulting on their creditcard payment. That would be 96.67% of total cases. One important fact: the data are quite imbalanced: very few cases are defaulting ont their credit card payment. This is an important fact, because if we would simply *predict* everyone to **not default on their credit card payment**, we would be 96.67% accurate. 

The `student` distribution is also imbalanced, but to a much less extreme extent. 2944 cases out of the 10000 observed are students. That is 29.44%. 

```{r warning=FALSE, message=FALSE}
Default %>% 
  ggpairs()
```

When we study the distribution plots we can identify the same information as in the tables. However, from the plots we can infer far more inctricate patternsthan from the tables alone. 

It is apparent that `student` is bimodal. One of the reasons for bimodality may be that there is a mixture of distributions for being a student or not being a student. When we study the above plots, this becomes very clear.

In the row and column `student` we can clearly see that there is a different distribution for `income`. That is, the distribution for `income` is less variable and has a lower mean for when `student` equals *Yes*. This of course makes sense: students generally have a lower income than non-students. Another feature that we see is that cases that `default` tend to have a higher `balance`. 

When we look at the boxplots, we see the same information as in the distribution plots, but now in terms of quartiles (each quart of the boxplot contains about 25% of cases) and the median *the bold line in the middle). The more symmetric a boxplot is, the more symmetric the data are distributed. 

---

_2_ **Study the relation between `default`, `income` and `balance`. Can we use these variables to predict creditcard `default`?**

```{r}
fit <- Default %$% 
  glm(default ~ income + balance, 
      family = binomial(link ="logit"))

AIC(fit)
BIC(fit)
```

Let's go through the output that we have generated. We start with the model summary:

*AIC* and *BIC* are model fit statistics. These statistics work on the scale of the log-likelihood. The log of zero (no deviance) would be $\text{log}(0) = -\inf$. These statistics take fit and complexity into account. Lower values are therefore preferred. AIC and BIC for a single model are not very informative, other than that you can see if the model is perfect or not. AIC and BIC are useful when comparing models.

```{r}
fit %>% 
  summary
```

With linear regression we had the `Sum of Squares (SS)`. Its logistic counterpart is the `Deviance (D)`. 

 -  Deviance is the fit of the observed values to the expected values. 
 
With logistic regression we aim to maximize the `likelihood`, which is equivalent to minimizing the deviance. The likelihood is the (joint) probability of the observed values, given the current model parameters.

In normally distributed data: $\text{SS}=\text{D}$.

---

The next output table gives us information on the coefficients We see that the coefficients are very low, yet both coefficients are significant. We must realize that both the columns `balance` and `income` are measured in a large scale, hence the estimates are expected to be lower in size (imagine writing down 1 kilogram in grams or in metric tonnes - you'd have two completely different numbers because of the different scales). 

The intercept denotes the estimate for the predicted outcome `default` when `balance` or `income` are zero. All estimates for the coefficients are logodds. The p-value comes from the Wald test that is used to determine statistical significance. The aim of the test it to test if the estimate is equal to zero (that is its null hypothesis). All estimates are highly significant. 

---

The next object that I'd like to consider is the confusion matrix.
```{r}
pred <- ifelse(predict(fit) > .5, "Yes", "No") %>% as.factor
confusionMatrix(pred, Default$default)
```

A confusion matrix gives an indication about the performance of a logistic prediction effort. The diagonal would indicate cases being predicted conform the observed classification, i.e. `No` as `No` and `Yes` as `Yes`. The off-diagonal indicates errors. It is often useful to study the prediction matrix, as not every error may have the same cost. For example, in health care some prediction mistakes could cost lives while others may cost only money. 



The last piece of output that we look at are the estimate plots.
```{r warning = FALSE, message = FALSE}
# for balance
Default %>%
  mutate(prob = predict(fit, type = "response")) %>%
  ggplot(aes(balance, prob)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial")) +
  xlab("Credit Card Balance") + 
  ylab("Predicted obability of default")

# for income
Default %>%
  mutate(prob = predict(fit, type = "response")) %>%
  ggplot(aes(income, prob)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "glm", 
              method.args = list(family = "binomial")) +
  xlab("Credit Card Balance") + 
  ylab("Predicted probability of default")
```

We can see a clear difference between `balance` and `income` in this estimation effort: the probability to default is relatively invariant with `income`, but not as clearly as with `balance`. A higher credit card balance is related to a larger probability to default. The turning point for having a higher probability than $.50$ lies just below a credit card balance of 2000.

---

_3_ **Now add `student` and study if there is a difference in the probability of creditcard fraud for students and non-students**

```{r}
fit2 <- Default %$% 
  glm(default ~ income + balance + student, 
      family = binomial(link ="logit"))
fit$deviance   # model without student
fit2$deviance  # model with student
AIC(fit, fit2)
BIC(fit, fit2)
```

First, we can see that the Deviance has decreased, as has the AIC. BIC increased slightly. That indicates an improvement in model fit, albeit a minimal improvement. 

```{r}
fit2 %>% summary %>% .$coefficients
```

From the coefficients table, we do see however that `income` is not a significant predictor anymore, when `student` is entered into the model. 

```{r}
pred <- ifelse(predict(fit2) > .5, "Yes", "No") %>% as.factor
confusionMatrix(pred, Default$default)
```

When studying the confusion matrix we see that the population of the diagonal for model `fit1` has decreased with respect to the previous model `fit`. So we have obtained a parametrically better model that makes more mistakes in predicting `default`. 

---

# Head Injury data
The `headInjury.csv` data frame has 3121 rows and 11 columns. The data were simulated according to a simple logistic regression model to match roughly the clinical characteristics of a sample of individuals who suffered minor head injuries.

---

The head injury data set contains information on the following variables:

This data frame contains the following columns:

- `age.65`: age factor (0 = under 65, 1 = over 65).
- `amnesia.before`: amnesia before impact (less than 30 minutes = 0, more than 30 minutes =1).
- `basal.skull.fracture`: (0 = no fracture, 1 = fracture).
- `GCS.decrease`: Glasgow Coma Scale decrease (0 = no deterioration, 1 = deterioration).
- `GCS.13`: initial Glasgow Coma Scale (0 = not ‘13’, 1 = ‘13’).
- `GCS.15.2hours`: Glasgow Coma Scale after 2 hours (0 = not ‘15’, 1 = '15').
- `high.risk`: assessed by clinician as high risk for neurological intervention (0 = not high risk, 1 = high risk).
- `loss.of.consciousness`: (0 = conscious, 1 = loss of consciousness).
- `open.skull.fracture`: (0 = no fracture, 1 = fracture)
- `vomiting`: (0 = no vomiting, 1 = vomiting)
- `clinically.important.brain.injury`: any acute brain finding revealed on CT (0 = not present, 1 = present).

---

_4_ **Patients whose risk is sufficiently high will be sent for CT (computed tomography). Using a risk threshold of 0.025 (2.5%), turn the result into a decision rule for use of CT.**

This may seem as a more difficult question, but it is actually quite straigthforward. First we need to fit the logistic model where we predict `clinically.important.brain.injury` from the other variables. 

```{r}
fit <- glm(clinically.important.brain.injury ~ ., 
           family = binomial(link = "logit"), 
           data = head.injury) 
summary(fit)
```

A risk of 2.5% corresponds to the cutoff for a CT scan. This translates to a logit of $\log\left(\frac{.025}{1-.025}\right) = -3.663562$. In other words, any sum of variables that "lifts" the intercept above -3.66 would satisfy the cutoff. 

For example, being over 65 (`age.65`) would already warrant a CT scan, as would coming into the ER with a basal skull fracture (`basal.skull.fracture`). Alternatively, having an open skull fracture (`open.skull.fracture`) alone is not enough to warrant a CT scan. It needs to be acompanied by any of the other significant checks in order to satisfy the risk threshold. 

---

# Titanic data

The `titanic` data set contains information on the fate of passengers on the fatal maiden voyage of the ocean liner ‘Titanic’. The task is to visualize the predicted probabilities of survival in two seperate plots: one plot for males and one plot for females. 

The data set [can be obtained here](Titanic.csv) or downloaded from the code block below.
```{r}
con <- url("https://www.gerkovink.com/rabobank/practicals/day2/R/Titanic.csv")
titanic <- read_csv(con)
```


---

_5_ **Load and inspect [the dataset](Titanic.csv) and fit a logistic regression model aimed at predicting survival from all other recorded features and all possible interactions between predictors**. 
```{r}
titanic %<>% mutate(Pclass = factor(Pclass), 
                 Sex = factor(Sex))
```

I transform the categorical column `Pclass` to a factor as well as the dichotomous column `Sex`. 

```{r}
fit <- titanic %$% 
  glm(Survived ~ Age * Pclass * Sex, family = binomial(link = "logit"))

fit %>% 
  summary
```
There are so many logodds to interpret, and the interactions make it quite challenging too. In such a case I'd often plot the predicted probabilities against a simulated data set. That makes it much simpler to interpret the effects. 

---

_6_ **Create a simulated data set where the rows represent each possible combination over the observed values of the predictors. Display the summary statistics for your simulated data set.** 

```{r}
sim <- titanic %>% 
  expand(Pclass, Sex, Age)
summary(sim)
```
We now have a simulated set that contains all possible interactions of all potential data combinations across `Pclass`, `Sex` and `Age`. 

---

_7_ **Apply the fitted model on the simulated data and add columns to your simulated data with the predicted logodds and probabilities and the standard error of each fitted value.**

```{r}
pred <- cbind(sim, 
              predict(fit, 
                      newdata = sim, 
                      type = "link", 
                      se = TRUE)) %>% 
  select(-residual.scale) %>% 
  mutate(prob = plogis(fit))
head(pred)
```

---

_8_ **Use `ggplot()` to display the plot of predicted survival probabilities vs all other features separately for males and females.**

```{r fig.width = 10, fig.height=6}
pred %>% 
  mutate(lower = plogis(fit - 1.96 * se.fit),     # lower prediction bound
         upper = plogis(fit + 1.96 * se.fit)) %>% # upper prediction bound
  ggplot(aes(y = prob, x = Age, fill = Pclass)) + 
  geom_ribbon(aes(ymin = lower, 
                  ymax = upper, 
                  fill = Pclass), 
              alpha = .2) +
  geom_line(aes(colour = Pclass), lwd = 1) + 
  ylab("Probability of Survival") + 
  xlab("Age of passenger") + 
  facet_wrap(vars(Sex)) + 
  scale_fill_discrete(name = "Pclass", 
                      labels = c("1st class", "2nd class", "3rd class")) +
  labs(colour = "Passenger class", fill = "Passenger class") +
  scale_colour_discrete(name = "Pclass", 
                        labels = c("1st class", "2nd class", "3rd class"))
  
```

I think this plot is much easier to interpret. 

---

End of exercise